from langgraph.graph import END, StateGraph
from langchain_core.messages import HumanMessage, AIMessage
from typing import Tuple, Optional

import streamlit as st
import time
import re
import requests
from bs4 import BeautifulSoup
from urllib.parse import urlparse
import logging
logger = logging.getLogger(__name__)
if not logger.handlers:
    logging.basicConfig(level=logging.INFO)

from src.states import AgentInput, AgentOutput, OverallState
from src.nodes import (
    question_rewriter,
    question_classifier,
    get_news,
    combine_news,
    on_topic_response,
    off_topic_response,
)
from src.edges import on_topic_router, news_router

workflow = StateGraph(OverallState, input=AgentInput, output=AgentOutput)

workflow.add_node(
    "question_rewriter",
    question_rewriter
)
workflow.add_node(
    "question_classifier",
    question_classifier
)
workflow.add_node('get_news', get_news)
workflow.add_node("combine_news", combine_news)
workflow.add_node("on_topic_response", on_topic_response)
workflow.add_node("off_topic_response", off_topic_response)


workflow.add_edge("question_rewriter", "question_classifier")
workflow.add_edge("get_news", "combine_news")
workflow.add_edge("combine_news", "on_topic_response")

workflow.add_conditional_edges(
    "question_classifier",
    on_topic_router,
    {
        "yes": "get_news",
        "no": "off_topic_response",
    }
)


workflow.add_conditional_edges(
    "combine_news",
    news_router,
    {
        "get_more_news": "get_news",
        "on_topic_response": "on_topic_response",
    }
)

workflow.add_edge("on_topic_response", END)
workflow.add_edge("off_topic_response", END)
workflow.set_entry_point("question_rewriter")
graph = workflow.compile()

#input_data = {"question": HumanMessage(content="What are the top five news of the day in AI and the food industry?")}
#result = graph.invoke(input_data)
#print(result)

#-------------------------------
# Streamlit app
#-------------------------------

# ---------- CONFIG ----------
st.set_page_config(page_title="NewsGeny", layout="wide")
st.title("ğŸ—ï¸ NewsGeny")

# ---------- INITIAL STATE ----------
if "last_response" not in st.session_state:
    st.session_state["last_response"] = ""
if "question_input" not in st.session_state:
    st.session_state["question_input"] = ""

# ---------- FUNCTION ----------
def extract_question_label(question: str) -> str:
    """
    Limpia la pregunta del usuario para usarla como etiqueta legible.
    Ejemplo:
      'What are the latest AI news in food industry?' â†’ 'AI news in food industry'
    """
    if not question:
        return ""

    q = question.strip()

    # Pasa todo a minÃºsculas para procesar
    q_clean = q.lower()

    # Elimina palabras comunes al inicio
    q_clean = re.sub(r'^(what( are| is)?( the)?|show me|give me|tell me( about)?|latest|news( on| about)?)\s+', '', q_clean)

    # Quita signos de puntuaciÃ³n finales
    q_clean = q_clean.rstrip('?.!,;:')

    # Capitaliza solo la primera letra para mostrar bonito
    q_label = q_clean[0].upper() + q_clean[1:] if q_clean else ""

    return q_label


def generate_response():
    question = st.session_state["question_input"].strip()

    if not question:
        st.warning("Please enter a question.")
        return

    # ğŸ”¹ Limpia variables anteriores antes de procesar
    st.session_state["last_response"] = ""
    question_label = extract_question_label(question)

    try:
        with st.spinner("ğŸ” Fetching latest news..."):
            # Ejecuta el grafo
            input_data = {"question": HumanMessage(content=question)}
            result = graph.invoke(input_data)

        ai_response = None

        # ğŸ§© 1ï¸âƒ£ Caso principal: el grafo devuelve un dict con mensajes
        if isinstance(result, dict) and "messages" in result:
            for msg in reversed(result["messages"]):
                if isinstance(msg, AIMessage) and msg.content.strip():
                    ai_response = msg.content.strip()
                    break

        # ğŸ§© 2ï¸âƒ£ Caso alternativo: el grafo devuelve un solo AIMessage
        elif isinstance(result, AIMessage) and result.content.strip():
            ai_response = result.content.strip()

        # ğŸ§© 3ï¸âƒ£ Fallback: busca texto plano por si acaso
        elif isinstance(result, dict):
            for val in result.values():
                if isinstance(val, str) and val.strip():
                    ai_response = val.strip()
                    break

        # ğŸ§© 4ï¸âƒ£ Si no hay respuesta del modelo (None o vacÃ­o)
        if not ai_response:
            st.session_state["last_response"] = (
                "âš ï¸ No response generated by the model â€” try rephrasing your question."
            )
            return

        # ğŸ§© 5ï¸âƒ£ Si la respuesta es de tipo â€œoff-topicâ€ (segÃºn tu nodo)
        if "unrelated to news" in ai_response.lower():
            st.session_state["last_response"] = (
                f"ğŸ§­ **Your question seems off-topic:** {ai_response}"
            )
            return

        # ğŸ§© 6ï¸âƒ£ Si hay respuesta vÃ¡lida â†’ formatear tÃ­tulo Markdown
        lines = ai_response.splitlines()
        if lines:
            # reemplaza la primera lÃ­nea si contiene el tÃ­tulo estÃ¡ndar
            if "Top 10 News Articles" in lines[0]:
                lines[0] = f"### ğŸ“° Top 10 News Articles on {question_label}"
            else:
                # si no hay tÃ­tulo, lo agrega al inicio
                lines.insert(0, f"### ğŸ“° Top 10 News Articles on {question_label}")
                lines.insert(1, "")
        else:
            lines = [f"### ğŸ“° Top 10 News Articles on {question_label}", ""]

        ai_response = "\n".join(lines)
        st.session_state["last_response"] = ai_response

    except Exception as e:
        st.error(f"âš ï¸ Error generating response: {e}")
    finally:
        # ğŸ”¹ Limpia el input siempre (aunque haya error)
        st.session_state["question_input"] = ""


# ---------- UI ----------
# ğŸ”¹ Input fijo arriba
st.markdown("### Ask for the latest news")
st.text_input(
    "What news are you looking for?",
    key="question_input",
    on_change=generate_response,
    placeholder="e.g., latest AI developments in healthcare",
)
st.button("Submit", on_click=generate_response)

st.markdown("---")

# ğŸ”¹ Resultado abajo
if st.session_state["last_response"]:
    response_text = st.session_state["last_response"]  # keep as string
    # Render once
    st.markdown(response_text, unsafe_allow_html=True, width="content")

